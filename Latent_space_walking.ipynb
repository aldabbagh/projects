{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aldabbagh/projects/blob/master/Latent_space_walking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimal KerasCV notebook for latent space walking via prompt interpolation\n",
        "\n",
        "Let's start by installing what we need."
      ],
      "metadata": {
        "id": "BqI1JSgJAMMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras_cv --upgrade --quiet\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "id": "drOxP4tp_O_-",
        "outputId": "a15926c4-930b-4d23-bfaf-96251ab8861a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 578.0 MB 18 kB/s \n",
            "\u001b[K     |████████████████████████████████| 394 kB 66.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 65.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 59.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 60.3 MB/s \n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be DOWNGRADED:\n",
            "  libcudnn8\n",
            "0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 2 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 1,392 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 6s (66.7 MB/s)\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n",
            "(Reading database ... 123919 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Enable mixed precision\n",
        "# (only do this if you have a recent NVIDIA GPU)\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# Instantiate the Stable Diffusion model\n",
        "model = keras_cv.models.StableDiffusion(img_height=512, img_width=512, jit_compile=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E65tu6ks_PhJ",
        "outputId": "1e7ac28b-37ad-43a1-b1c0-c0ea87d65cd9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n",
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 6s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 44s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5\n",
            "198180272/198180272 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a gif saving utility that will come in handy."
      ],
      "metadata": {
        "id": "UXauh8XbCUye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_as_gif(filename, images, frames_per_second=13, rubber_band=False):\n",
        "    if rubber_band:\n",
        "        images += images[2:-1][::-1]\n",
        "    images[0].save(\n",
        "        filename,\n",
        "        save_all=True,\n",
        "        append_images=images[1:],\n",
        "        duration=1000 // frames_per_second,\n",
        "        loop=0,\n",
        "    )"
      ],
      "metadata": {
        "id": "MY4G3qB1_PmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## These are our configurable parameters\n",
        "\n",
        "We will walk from `prompt1` to `prompt2`."
      ],
      "metadata": {
        "id": "LVNnRKC3AYJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = \"Mysterious ruins in the snow, concept art, digital, artstation\"\n",
        "prompt_2 = \"Mysterious ruins in the summer sunlight, concept art, digital, artstation\"\n",
        "interpolation_steps = 50\n",
        "filename = \"ruins_1.gif\""
      ],
      "metadata": {
        "id": "SPECIuQvAYSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's generate"
      ],
      "metadata": {
        "id": "Vk5eUkljAisU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Goa_4X1f_JZ-",
        "outputId": "64543505-7810-42a0-e15e-14aeeac8744b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 9s 339ms/step\n",
            "25/25 [==============================] - 9s 340ms/step\n",
            "25/25 [==============================] - 8s 339ms/step\n",
            "25/25 [==============================] - 8s 339ms/step\n",
            "25/25 [==============================] - 8s 339ms/step\n"
          ]
        }
      ],
      "source": [
        "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
        "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
        "\n",
        "batch_size = 10 # This value might to be lowered to 3 on a smaller GPU.\n",
        "batches = interpolation_steps // batch_size\n",
        "\n",
        "interpolated_encodings = tf.linspace(encoding_1, encoding_2, interpolation_steps)\n",
        "batched_encodings = tf.split(interpolated_encodings, batches)\n",
        "\n",
        "seed = 1337\n",
        "noise = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)\n",
        "\n",
        "images = []\n",
        "for batch in range(batches):\n",
        "    images += [\n",
        "        Image.fromarray(img)\n",
        "        for img in model.generate_image(\n",
        "            batched_encodings[batch],\n",
        "            batch_size=batch_size,\n",
        "            num_steps=25,\n",
        "            diffusion_noise=noise,\n",
        "        )\n",
        "    ]\n",
        "\n",
        "export_as_gif(filename, images, rubber_band=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the generated gif, look for the file browser tab on your left."
      ],
      "metadata": {
        "id": "mPURrGgxBX_a"
      }
    }
  ]
}